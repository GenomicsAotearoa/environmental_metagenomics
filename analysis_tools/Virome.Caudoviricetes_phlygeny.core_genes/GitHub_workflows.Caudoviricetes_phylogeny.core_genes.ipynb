{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow: Caudoviricetes phylogeny \n",
    "\n",
    "Workflow for inference of Caudoviricetes phylogeny via concatenated protein alignments of putative single copy core genes\n",
    "\n",
    "Based on the method of Low *et al.* (2019) [here](https://doi.org/10.1038/s41564-019-0448-z)\n",
    "\n",
    "Method: \n",
    "\n",
    "- Previous analyses (Low *et al.* 2019) used 2017 version of VOG and the identified IDs are no longer compatible with the latest version\n",
    "- in brief, the workflow below: \n",
    "  - re-identifies putative single copy core genes in Caudoviricetes viruses broadly following the method of Low *et al.* (2019), using latest viralRefSeq references and the latest VOG database\n",
    "  - extracts the identified putative core genes from viralRefSeq references and Waiwera vOTUs\n",
    "  - generates filtered concatenated core gene protein alignments for all Caudoviricetes viruses\n",
    "  - build trees to infer phlyogeny and for visualisation of in iTol\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VOG database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir -p vogdb_v222_2024_04_10\n",
    "\n",
    "wget -r --no-parent https://fileshare.csb.univie.ac.at/vog/latest/ -P vogdb_v222_2024_04_10/\n",
    "mv vogdb_v222_2024_04_10/fileshare.csb.univie.ac.at/vog/latest/* vogdb_v222_2024_04_10/\n",
    "rm -r vogdb_v222_2024_04_10/fileshare.csb.univie.ac.at/\n",
    "\n",
    "#untar hmm profiles file and cat for downstream use\n",
    "cd vogdb_v222_2024_04_10\n",
    "tar -xzf vog.hmm.tar.gz\n",
    "cat hmm/*.hmm > vogdb_all_hmm.hmm\n",
    "\n",
    "tar -xzf vog.faa.tar.gz\n",
    "gunzip vogdb.proteins.all.fa.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### viralRefSeq references"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download latest database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir -p viralRefSeq_2024_04_10\n",
    "\n",
    "wget https://ftp.ncbi.nlm.nih.gov/refseq/release/viral/viral.1.1.genomic.fna.gz -P viralRefSeq_2024_04_10/\n",
    "wget https://ftp.ncbi.nlm.nih.gov/refseq/release/viral/viral.1.protein.faa.gz -P viralRefSeq_2024_04_10/\n",
    "wget https://ftp.ncbi.nlm.nih.gov/refseq/release/viral/viral.1.genomic.gbff.gz -P viralRefSeq_2024_04_10/\n",
    "wget https://ftp.ncbi.nlm.nih.gov/refseq/release/viral/viral.1.protein.gpff.gz  -P viralRefSeq_2024_04_10/\n",
    "\n",
    "gunzip viralRefSeq_2024_04_10/*.gz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter RefSeq by taxonomy (Caudoviricetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd viralRefSeq_2024_04_10\n",
    "\n",
    "module purge\n",
    "module load Python/3.11.3-gimkl-2022a\n",
    "python3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "\n",
    "### Genomic files\n",
    "metadata_dfs = []\n",
    "with open('viral.1.genomic.gbff', 'r') as genbank_infile:\n",
    "    with open('Caudoviricetes.genomic.fna', 'w') as write_fasta:\n",
    "        for seq_record in SeqIO.parse(genbank_infile, \"genbank\") :\n",
    "            if 'Caudoviricetes' in seq_record.annotations['taxonomy']:\n",
    "                write_fasta.write(\">%s\\n%s\\n\" % (\n",
    "                    seq_record.id,\n",
    "                    str(seq_record.seq)))\n",
    "                try:\n",
    "                    host = seq_record.features[0].qualifiers['host'][0]\n",
    "                except Exception as e:\n",
    "                  host = np.nan\n",
    "                metadata_dfs.append(pd.DataFrame({'genomeID': seq_record.id, 'full_taxonomy': ';'.join(seq_record.annotations['taxonomy']), 'host': host}, index=[0]))\n",
    "\n",
    "df = pd.concat(metadata_dfs).reset_index(drop=True)\n",
    "\n",
    "# separate taxonomy into ranks based on suffix extraction\n",
    "df['domain'] = np.where(df['full_taxonomy'].astype(str).str.contains('(Viruses).*'), df['full_taxonomy'].astype(str).str.replace(pat='(Viruses).*', repl='\\\\1', regex=True), 'Unclassified')\n",
    "tax_rank = ['realm', 'subrealm', 'kingdom', 'subkingdom', 'phylum', 'subphylum', 'class', 'subclass', 'order', 'suborder', 'family', 'subfamily', 'genus']\n",
    "suffix_str = ['viria', 'vira', 'virae', 'virites', 'viricota', 'viricotina', 'viricetes', 'viricetidae', 'virales', 'virineae', 'viridae', 'virinae', 'virus']\n",
    "for i in range(len(tax_rank)):\n",
    "    df[tax_rank[i]] = np.where(df['full_taxonomy'].astype(str).str.contains('.*;(.*'+suffix_str[i]+').*'), df['full_taxonomy'].astype(str).str.replace(pat='.*;(.*'+suffix_str[i]+').*', repl='\\\\1', regex=True), 'Unclassified')\n",
    "\n",
    "df['species'] = np.where(df['full_taxonomy'].astype(str).str.contains('.*;(.*virus .*)'), df['full_taxonomy'].astype(str).str.replace(pat='.*;(.*virus .*)', repl='\\\\1', regex=True), 'Unclassified')\n",
    "\n",
    "# write out metadata file\n",
    "df.to_csv('Caudoviricetes.genomic.metadata.tsv', sep='\\t', index=False)\n",
    "\n",
    "quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run CheckV to assess predicted completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module load CheckV/0.7.0-gimkl-2020a-Python-3.8.2\n",
    "\n",
    "mkdir -p checkv_out\n",
    "\n",
    "checkv end_to_end viralRefSeq_2024_04_10/Caudoviricetes.genomic.fna checkv_out -t 16 --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Slurm runtime < 40 hr; MaxRSS < 8 GB*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run DRAMv on Caudoviricetes references"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DRAM-v Prep: Split fasta file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir -p RefSeq/DRAMv/vsort2_prepfiles/split_input_fasta\n",
    "\n",
    "module load BBMap/38.95-gimkl-2020a\n",
    "\n",
    "partition.sh \\\n",
    "in=viralRefSeq_2024_04_10/Caudoviricetes.genomic.fna \\\n",
    "out=RefSeq/DRAMv/vsort2_prepfiles/split_input_fasta/refseq_caudoviricetes_%.fna ways=100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DRAM-v Prep: VirSorter2\n",
    "\n",
    "Note: run as a slurm array (`#SBATCH --array=0-99`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "module load VirSorter/2.2.3-gimkl-2020a-Python-3.8.2\n",
    "\n",
    "# Set up working directories\n",
    "mkdir -p RefSeq/DRAMv/vsort2_prepfiles/subsets\n",
    "\n",
    "# run virsorter2\n",
    "virsorter run -j 24 \\\n",
    "--seqname-suffix-off --viral-gene-enrich-off --provirus-off --prep-for-dramv \\\n",
    "-i RefSeq/DRAMv/vsort2_prepfiles/split_input_fasta/refseq_caudoviricetes_${SLURM_ARRAY_TASK_ID}.fna \\\n",
    "-d Databases/virsorter2_20210909/ \\\n",
    "--min-score 0 --include-groups dsDNAphage,NCLDV,RNA,ssDNA,lavidaviridae \\\n",
    "-l refseq_caudoviricetes_${SLURM_ARRAY_TASK_ID} \\\n",
    "-w RefSeq/DRAMv/vsort2_prepfiles/subsets/refseq_caudoviricetes_${SLURM_ARRAY_TASK_ID} \\\n",
    "--tmpdir ${SLURM_JOB_ID}.tmp \\\n",
    "--rm-tmpdir \\\n",
    "all \\\n",
    "--config LOCAL_SCRATCH=${TMPDIR:-/tmp}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Slurm runtime < 40 min; MaxRSS < 1 GB*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DRAM-v: annotate\n",
    "\n",
    "Note: run as a slurm array (`#SBATCH --array=0-99%20`)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "mkdir -p RefSeq/DRAMv/dramv_annotation\n",
    "\n",
    "# Load DRAM (conda install)\n",
    "module load Miniconda3/4.12.0\n",
    "export CONDA_PKGS_DIRS=.conda/pkgs\n",
    "export CONDA_ENVS_PATH=.conda/envs\n",
    "\n",
    "# Run DRAM\n",
    "source activate DRAM_1.4.6\n",
    "DRAM-v.py annotate --threads 32 \\\n",
    "--min_contig_size 1000 \\\n",
    "-i RefSeq/DRAMv/vsort2_prepfiles/subsets/refseq_caudoviricetes_${SLURM_ARRAY_TASK_ID}/refseq_caudoviricetes_${SLURM_ARRAY_TASK_ID}-for-dramv/final-viral-combined-for-dramv.fa \\\n",
    "-v RefSeq/DRAMv/vsort2_prepfiles/subsets/refseq_caudoviricetes_${SLURM_ARRAY_TASK_ID}/refseq_caudoviricetes_${SLURM_ARRAY_TASK_ID}-for-dramv/viral-affi-contigs-for-dramv.tab \\\n",
    "-o RefSeq/DRAMv/dramv_annotation/dramv_annotation_subset_${SLURM_ARRAY_TASK_ID}\n",
    "\n",
    "conda deactivate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Slurm runtime < 20 hr; MaxRSS < 16 GB*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DRAM-v: Compile DRAM-v annotation subsets and genes files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working directory\n",
    "cd /nesi/nobackup/ga02676/Waiwera_project/mikeh_Vir/MetaG/7b.Caudoviricetes/core_genes/RefSeq/DRAMv\n",
    "\n",
    "# Load python\n",
    "module purge\n",
    "module load Python/3.8.2-gimkl-2020a\n",
    "\n",
    "# Run compile dram annotations\n",
    "compile_dram_annotations.py \\\n",
    "-i RefSeq/DRAMv/dramv_annotation \\\n",
    "-o RefSeq/DRAMv/dramv_annotation/collated_dramv_\n",
    "\n",
    "# cat genes files\n",
    "cat RefSeq/DRAMv/dramv_annotation/*/genes.faa > RefSeq/DRAMv/collated_dram_genes.faa\n",
    "cat RefSeq/DRAMv/dramv_annotation/*/genes.fna > RefSeq/DRAMv/collated_dram_genes.fna\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM search of VOGdb HMMs against RefSeq references\n",
    "\n",
    "- n.b. using downloaded VOGdb file vog.hmm.tar.gz (Compressed archive of the HMMER3 compatible Hidden Markov Models obtained from the multiple sequence alignments for each VOG)\n",
    "- running with the genes.faa file output from DRAMv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir -p RefSeq/VOGdb_hmmsearch\n",
    "\n",
    "module load HMMER/3.3.2-GCC-11.3.0\n",
    "\n",
    "hmmsearch -E 1e-3 --cpu 24 \\\n",
    "--tblout RefSeq/VOGdb_hmmsearch/viralRefSeq.all_genes.vogdb \\\n",
    "--domtblout RefSeq/VOGdb_hmmsearch/viralRefSeq.all_genes.domain_hits.vogdb \\\n",
    "vogdb_v222_2024_04_10/vogdb_all_hmm.hmm \\\n",
    "RefSeq/DRAMv/collated_dram_genes.faa > /dev/null\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Slurm runtime < 16 hr; MaxRSS < 8 GB*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM search of VOGdb HMMs against vOTUs\n",
    "\n",
    "- running with the genes.faa file output from DRAMv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir -p vOTUs/VOGdb_hmmsearch\n",
    "\n",
    "module load HMMER/3.3.2-GCC-11.3.0\n",
    "\n",
    "srun hmmsearch -E 1e-3 --cpu 24 \\\n",
    "--tblout vOTUs/VOGdb_hmmsearch/votus.vogdb \\\n",
    "--domtblout vOTUs/VOGdb_hmmsearch/votus.domain_hits.vogdb \\\n",
    "vogdb_v222_2024_04_10/vogdb_all_hmm.hmm \\\n",
    "vOTUs/dramv_annotation.genes.faa > /dev/null\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Slurm runtime < 12 hr; MaxRSS < 4GB*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess Caudoviricetes viralRefSeq VOGdb gene hits for putative single copy core genes\n",
    "\n",
    "Method:\n",
    "\n",
    "- Filter references for >= 95% completeness (predicted via CheckV)\n",
    "- Select markers based on the following criteria: \n",
    "  - (1) present in ≥10% of bacterial and archaeal virus genomes\n",
    "  - (2) average copy number ≤1.2\n",
    "  - (3) average protein length >100 amino acid residues. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd RefSeq/VOGdb_hmmsearch\n",
    "\n",
    "module purge\n",
    "module load Python/3.11.3-gimkl-2022a\n",
    "python3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from glob import glob\n",
    "from Bio.SeqIO.FastaIO import SimpleFastaParser\n",
    "\n",
    "df = pd.read_csv('viralRefSeq.all_genes.vogdb', comment='#', header=None, delimiter=r\"\\s+\", usecols=[*range(0,18)]).reset_index(drop=True)\n",
    "df.columns = ['target_name','accession','query_name','accession','fullSeq_eval','fullSeq_score','fullSeq_bias','bestDomain_eval','bestDomain_score','bestDomain_bias','exp','reg','clu','ov','env','dom','rep','inc']     \n",
    "df['genomeID'] = df['target_name'].str.replace('-cat_.*', '', regex=True)\n",
    "\n",
    "# Only keep match with lowest full seq eval for each geneID\n",
    "df = df.sort_values(by=[\"target_name\", \"fullSeq_eval\"], ascending=[True, True])\n",
    "df = df.groupby(\"target_name\", as_index=False).first()\n",
    "\n",
    "# filter for high-quality and/or complete genomes\n",
    "checkv_df = pd.read_csv('../checkv_out/quality_summary.tsv', delimiter=\"\\t\")\n",
    "checkv_df = checkv_df[checkv_df['completeness'] >= 95].reset_index(drop=True)\n",
    "df = df[df['genomeID'].isin(checkv_df['contig_id'].values)]\n",
    "\n",
    "# Write out\n",
    "df.to_csv('Refseq_vogdb_hmmsearch.compiled.tsv', sep='\\t', index=False)\n",
    "\n",
    "# VOGdb hits per genome\n",
    "vog_counts_df = df.groupby('genomeID')[\"query_name\"].apply(lambda x: x.groupby(x).size()).reset_index().pivot(index='genomeID', columns='level_1', values='query_name').reset_index()\n",
    "# Select vog hits based on criteria listed above\n",
    "## present in more than 10% of genomes\n",
    "vog_counts_df = vog_counts_df.dropna(thresh=int(len(vog_counts_df)*0.1), axis=1)\n",
    "## average copy number ≤1.2\n",
    "cols_mean = vog_counts_df.mean(axis=0, numeric_only=True)\n",
    "drop_cols = cols_mean[cols_mean >= 1.2].index\n",
    "vog_counts_df.drop(columns=drop_cols, inplace=True)\n",
    "vogIDs_to_keep = [col for col in vog_counts_df.columns if col != 'genomeID']\n",
    "## average protein length >100 amino acid residues\n",
    "seq_files = sorted(glob('../DRAMv/dramv_annotation/dramv_annotation_subset_*/genes.faa'))\n",
    "seq_dict = {}\n",
    "for seq_file in seq_files:\n",
    "    with open(seq_file, 'r') as read_fasta:\n",
    "        for name, seq in SimpleFastaParser(read_fasta):\n",
    "            name_trim = re.sub(r' .*', r'', name)\n",
    "            seq_dict[name_trim] = len(seq)\n",
    "\n",
    "genes_df = df.merge(pd.DataFrame(seq_dict.items(), columns=['geneID','aa_seq_length']), how='left', left_on='target_name', right_on='geneID')\n",
    "genes_df = genes_df[genes_df['query_name'].isin(vogIDs_to_keep)]\n",
    "mean_seq_len_df = genes_df.groupby('query_name', as_index=False)['aa_seq_length'].mean()\n",
    "\n",
    "# final filtered list of vogIDs\n",
    "final_vogIDs = mean_seq_len_df[mean_seq_len_df['aa_seq_length'] >= 100]['query_name'].values.tolist()\n",
    "# counts table of vogs per genome\n",
    "vog_counts_final_df = vog_counts_df[['genomeID']+[col for col in vog_counts_df.columns if col in final_vogIDs]]\n",
    "# write out\n",
    "vog_counts_final_df.to_csv('Refseq_vogdb.core_genes.countTable.tsv', sep='\\t', index=False)\n",
    "\n",
    "# compile table of final vogIDs w/annotations\n",
    "vog_annot = pd.read_csv('vogdb_v222_2024_04_10/vog.annotations.tsv', delimiter=\"\\t\")\n",
    "vog_annot = vog_annot[vog_annot['#GroupName'].isin(final_vogIDs)].reset_index(drop=True).rename(columns={'#GroupName': 'vogdb_id'})\n",
    "vog_annot = vog_annot[['vogdb_id', 'FunctionalCategory', 'ConsensusFunctionalDescription']]\n",
    "# write out\n",
    "vog_annot.to_csv('Refseq_vogdb.core_genes.annotations.tsv', sep='\\t', index=False)\n",
    "\n",
    "quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "## Collate core genes for viralRefSeq references and vOTUs\n",
    "\n",
    "- Method:\n",
    "  - filter datasets to retain only genomes with predicted completeness >= 85%\n",
    "  - extract gene matches based on vogdb_id core genes identified above\n",
    "  - for each gene: write out faa file of sequences to align (and then concatenate after alignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir -p faa_files/hmmsearch_results_85\n",
    "\n",
    "module purge\n",
    "module load Python/3.9.9-gimkl-2020a\n",
    "python3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from Bio.SeqIO.FastaIO import SimpleFastaParser\n",
    "\n",
    "# marker genes\n",
    "marker_genes_df = pd.read_csv(\"RefSeq/VOGdb_hmmsearch/Refseq_vogdb.core_genes.annotations.tsv\", sep='\\t').drop('FunctionalCategory', axis=1)\n",
    "marker_genes_dict = dict(marker_genes_df.values)\n",
    "\n",
    "### RefSeq\n",
    "vog_df = pd.read_csv('RefSeq/VOGdb_hmmsearch/viralRefSeq.all_genes.vogdb', comment='#', header=None, delimiter=r\"\\s+\", usecols=[*range(0,18)]).reset_index(drop=True)\n",
    "vog_df.columns = ['target_name','accession','query_name','accession','fullSeq_eval','fullSeq_score','fullSeq_bias','bestDomain_eval','bestDomain_score','bestDomain_bias','exp','reg','clu','ov','env','dom','rep','inc']     \n",
    "vog_df['genomeID'] = vog_df['target_name'].str.replace('-cat_.*', '', regex=True)\n",
    "vog_df['target_name'] = vog_df['target_name'].str.replace('-cat_\\d+', '', regex=True)\n",
    "# Only keep match with lowest full seq eval for each geneID\n",
    "vog_df = vog_df.sort_values(by=[\"target_name\", \"fullSeq_eval\"], ascending=[True, True])\n",
    "vog_df = vog_df.groupby(\"target_name\", as_index=False).first()\n",
    "# filter based on completeness\n",
    "checkv_df = pd.read_csv('RefSeq/checkv_out/quality_summary.tsv', delimiter=\"\\t\")\n",
    "checkv_df = checkv_df[checkv_df['completeness'] >= 85].reset_index(drop=True)\n",
    "refseq_df = vog_df[vog_df['genomeID'].isin(checkv_df['contig_id'].values)]\n",
    "\n",
    "### vOTUs\n",
    "# Caudovirales vOTU IDs\n",
    "tax_predict = pd.read_csv(\"vOTU.tax_predict_table.tsv\", sep='\\t')\n",
    "caudo_votu_ids = tax_predict[tax_predict['Class_combined_prediction'] == 'Caudoviricetes']['Genome'].values.tolist()\n",
    "# vog results\n",
    "votu_df = pd.read_csv('vOTUs/VOGdb_hmmsearch/votus.vogdb', comment='#', header=None, delimiter=r\"\\s+\", usecols=[*range(0,18)]).reset_index(drop=True)\n",
    "votu_df.columns = ['target_name','accession','query_name','accession','fullSeq_eval','fullSeq_score','fullSeq_bias','bestDomain_eval','bestDomain_score','bestDomain_bias','exp','reg','clu','ov','env','dom','rep','inc']     \n",
    "votu_df['genomeID'] = votu_df['target_name'].str.replace('-cat_.*', '', regex=True)\n",
    "votu_df['target_name'] = votu_df['target_name'].str.replace('-cat_\\d+', '', regex=True)\n",
    "# Only keep match with lowest full seq eval for each geneID\n",
    "votu_df = votu_df.sort_values(by=[\"target_name\", \"fullSeq_eval\"], ascending=[True, True])\n",
    "votu_df = votu_df.groupby(\"target_name\", as_index=False).first()\n",
    "# subset vOTUs_50 caudoviricetes\n",
    "votu_df = votu_df[votu_df['genomeID'].isin(caudo_votu_ids)]\n",
    "# filter based on completeness\n",
    "checkv_df = pd.read_csv('checkv_vOTUs/vOTUs.quality_summary.tsv', delimiter=\"\\t\")\n",
    "checkv_df = checkv_df[checkv_df['completeness'] >= 85].reset_index(drop=True)\n",
    "votu_df = votu_df[votu_df['genomeID'].isin(checkv_df['contig_id'].values)]\n",
    "\n",
    "### Extract marker genes, write sequences to new faa files\n",
    "# faa files for: RefSeq references; Waiwera vOTUs; RefSeq references and vOTUs combined\n",
    "for marker_gene in marker_genes_dict.keys():\n",
    "    refseq_marker_gene_geneIDs = refseq_df[refseq_df['query_name'] == marker_gene].reset_index(drop=True)['target_name'].values.tolist()\n",
    "    votu_marker_gene_geneIDs = votu_df[votu_df['query_name'] == marker_gene].reset_index(drop=True)['target_name'].values.tolist()\n",
    "    # generate faa files of amino acid sequences\n",
    "    with open('RefSeq/DRAMv/collated_dram_genes.faa', 'r') as read_fasta:\n",
    "        with open('faa_files/hmmsearch_results_85/refseq.'+marker_gene+'.faa', 'w') as write_refseq_faa:\n",
    "            with open('faa_files/hmmsearch_results_85/combined.'+marker_gene+'.faa', 'w') as write_combined_faa:\n",
    "                for name, seq in SimpleFastaParser(read_fasta):\n",
    "                    gene_id = re.sub(r'(.*)-cat_\\d+(_\\d*).*', r'\\1\\2', name)\n",
    "                    if gene_id in refseq_marker_gene_geneIDs:\n",
    "                        write_refseq_faa.write('>' + str(gene_id) + '_' + marker_gene + '\\n' + str(seq) + '\\n')\n",
    "                        write_combined_faa.write('>' + str(gene_id) + '_' + marker_gene + '\\n' + str(seq) + '\\n')\n",
    "    with open('vOTUs/dramv_annotation.genes.faa', 'r') as read_fasta:\n",
    "        with open('faa_files/hmmsearch_results_85/votus.'+marker_gene+'.faa', 'w') as write_votu_faa:\n",
    "            with open('faa_files/hmmsearch_results_85/combined.'+marker_gene+'.faa', 'a') as write_combined_faa:\n",
    "                for name, seq in SimpleFastaParser(read_fasta):\n",
    "                    gene_id = re.sub(r'(.*)-cat_\\d+(_\\d*).*', r'\\1\\2', name)\n",
    "                    if gene_id in votu_marker_gene_geneIDs:\n",
    "                        write_votu_faa.write('>' + str(gene_id) + '_' + marker_gene + '\\n' + str(seq) + '\\n')\n",
    "                        write_combined_faa.write('>' + str(gene_id) + '_' + marker_gene + '\\n' + str(seq) + '\\n')\n",
    "\n",
    "\n",
    "quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gene alignments for each marker gene"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "caudo_core_genes_alignments_combined.sl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -A <>\n",
    "#SBATCH -J caudo_core_genes_alignments_combined\n",
    "#SBATCH --time 00:30:00\n",
    "#SBATCH --mem=1GB\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=16\n",
    "#SBATCH -e caudo_core_genes_alignments_combined_%a.err\n",
    "#SBATCH -o caudo_core_genes_alignments_combined_%a.out\n",
    "\n",
    "mkdir -p alignments/hmmsearch_results_85\n",
    "\n",
    "file_list=( $(ls faa_files/hmmsearch_results_85/combined.*) )\n",
    "file_id=${file_list[${SLURM_ARRAY_TASK_ID}]}\n",
    "out_id=$(basename ${file_id} .faa)\n",
    "\n",
    "module purge\n",
    "module load Clustal-Omega/1.2.4-gimkl-2020a\n",
    "\n",
    "clustalo -i ${file_id} -o alignments/hmmsearch_results_85/aln.${out_id}.faa --outfmt=fa --log=alignments/hmmsearch_results_85/aln.${out_id}.log --threads=16 --force\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run slurm array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "file_list=( $(ls faa_files/hmmsearch_results_85/combined.*) )\n",
    "ZNUM=$(( ${#file_list[@]} - 1 ))\n",
    "\n",
    "sbatch --array=0-${ZNUM} caudo_core_genes_alignments_combined.sl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Slurm runtime < 15 min; MaxRss < 1 GB*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate protein alignments for all genomes\n",
    "\n",
    "- Concantenate above alignments into a single file\n",
    "- Filter based on criteria from Low *et al.* (2019)\n",
    "  - NOTEs from Low *et al.* for these steps:\n",
    "    - The length of all markers combined before trimming was 26,165 amino acids\n",
    "    - All marker MSAs were individually trimmed by **removing columns represented in <50% of taxa**. \n",
    "    - The individual alignments were concatenated by **introducing gaps in positions where markers were absent from a genome**\n",
    "    - The resulting concatenated MSA of 23,531 columns was further filtered to **remove 182 genomes with <5% amino acid representation of the total alignment length**, producing a final matrix of 1,803 genomes× 23,531 columns with **84% missing data**.\n",
    "    - The CCP77 reference tree was inferred from the MSA using **IQ-TREE** version 1.5.5 under the **partitioned LG + GAMMA model** and **midpoint rooted**, followed by **100 nonparametric bootstrap replicates** to estimate branch support.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RefSeq and vOTUs combined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir -p concat_alignments/hmmsearch_results_85\n",
    "\n",
    "module purge\n",
    "module load Python/3.9.9-gimkl-2020a\n",
    "python3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from Bio.SeqIO.FastaIO import SimpleFastaParser\n",
    "\n",
    "# vog IDs\n",
    "marker_genes_df = pd.read_csv(\"RefSeq/VOGdb_hmmsearch/Refseq_vogdb.core_genes.annotations.tsv\", sep='\\t').drop('FunctionalCategory', axis=1)\n",
    "marker_genes_dict = dict(marker_genes_df.values)\n",
    "\n",
    "# establish df\n",
    "concat_alignments_df = pd.DataFrame(columns=['genomeID'])\n",
    "\n",
    "# loop throgh each alignment, create as df, join with running full df\n",
    "for vog_id in marker_genes_dict.keys():\n",
    "    aa_seqs_dict = {}\n",
    "    with open('alignments/hmmsearch_results_85/aln.combined.'+vog_id+'.faa', 'r') as read_fasta:\n",
    "        for name, seq in SimpleFastaParser(read_fasta):\n",
    "            aa_seqs_dict[name] = seq\n",
    "    aa_seqs_df = pd.DataFrame(aa_seqs_dict.items(), columns=['geneID', 'seq_alignment'])\n",
    "    aa_seqs_df['genomeID'] = aa_seqs_df['geneID'].str.replace('_\\d+_VOG.*', '', regex=True)\n",
    "    # if more than one gene for this vog in a genome, just take the first alignment\n",
    "    aa_seqs_df = aa_seqs_df.drop_duplicates(subset='genomeID', keep=\"first\")\n",
    "    # split alignment into columns\n",
    "    aa_seqs_df = pd.concat([aa_seqs_df['genomeID'], aa_seqs_df['seq_alignment'].apply(lambda x: pd.Series(list(x)))], axis=1)\n",
    "    aa_seqs_df = aa_seqs_df.rename(columns={c: str(vog_id)+'_pos_'+str(c) for c in aa_seqs_df.columns if c not in ['genomeID']})\n",
    "    # replace all * with '-'\n",
    "    aa_seqs_df = aa_seqs_df.replace('*', '-')\n",
    "    ## remove columns present in less than 50% of genomes\n",
    "    aa_seqs_df = aa_seqs_df.replace('-', np.nan)\n",
    "    aa_seqs_df = aa_seqs_df.dropna(thresh=int(len(aa_seqs_df)*0.5), axis=1)\n",
    "    concat_alignments_df = concat_alignments_df.merge(aa_seqs_df, how=\"outer\", on='genomeID')\n",
    "\n",
    "# sort by genomeID\n",
    "concat_alignments_df = concat_alignments_df.sort_values('genomeID').reset_index(drop=True)\n",
    "# calculate number of columns remaining (i.e. number of amino acids)\n",
    "len(concat_alignments_df.columns)-1\n",
    "#13415\n",
    "# count genomes\n",
    "genomes_count = len(concat_alignments_df)\n",
    "print(genomes_count)\n",
    "#5246\n",
    "# remove genomes with <5% amino acid representation of the total alignment length\n",
    "concat_alignments_df = concat_alignments_df.dropna(subset=[col for col in concat_alignments_df.columns if col != 'genomeID'], thresh=int((len(concat_alignments_df.columns)-1)*0.05), axis=0).reset_index(drop=True)\n",
    "# count filtered genomes\n",
    "genomes_filt_count = len(concat_alignments_df)\n",
    "print(genomes_filt_count)\n",
    "#4481\n",
    "print(genomes_count - genomes_filt_count)\n",
    "#765 'genomes' removed\n",
    "\n",
    "# Calculate % missing data\n",
    "concat_alignments_df[[col for col in concat_alignments_df.columns if col != 'genomeID']].isna().mean().mean()\n",
    "# 0.8494473913670058 = 85% missing data\n",
    "\n",
    "# replace all nan with '-'\n",
    "concat_alignments_df = concat_alignments_df.replace(np.nan, '-')\n",
    "\n",
    "# Write out concatenated alignment file\n",
    "concat_alignments_df['seq_alignment'] = concat_alignments_df[[col for col in concat_alignments_df.columns if col != 'genomeID']].astype(str).agg(''.join, axis=1)\n",
    "concat_alignments_df = concat_alignments_df[['genomeID', 'seq_alignment']]\n",
    "concat_alignments_dict = dict(concat_alignments_df.values)\n",
    "with open('concat_alignments/hmmsearch_results_85/combined.core_genes.concatenated_alignment.faa', 'w') as write_faa:\n",
    "    for key,value in concat_alignments_dict.items():\n",
    "        write_faa.write('>' + str(key) + '\\n' + str(value) + '\\n')\n",
    "\n",
    "quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vOTUs only (filter out of combined alignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir -p concat_alignments/hmmsearch_results_85\n",
    "\n",
    "module purge\n",
    "module load Python/3.9.9-gimkl-2020a\n",
    "python3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from Bio.SeqIO.FastaIO import SimpleFastaParser\n",
    "\n",
    "# vog IDs\n",
    "marker_genes_df = pd.read_csv(\"RefSeq/VOGdb_hmmsearch/Refseq_vogdb.core_genes.annotations.tsv\", sep='\\t').drop('FunctionalCategory', axis=1)\n",
    "marker_genes_dict = dict(marker_genes_df.values)\n",
    "\n",
    "# establish df\n",
    "concat_alignments_df = pd.DataFrame(columns=['genomeID'])\n",
    "\n",
    "# loop throgh each alignment, create as df, join with running full df\n",
    "for vog_id in marker_genes_dict.keys():\n",
    "    aa_seqs_dict = {}\n",
    "    with open('alignments/hmmsearch_results_85/aln.combined.'+vog_id+'.faa', 'r') as read_fasta:\n",
    "        for name, seq in SimpleFastaParser(read_fasta):\n",
    "            if 'vOTU' in name:\n",
    "                aa_seqs_dict[name] = seq\n",
    "    aa_seqs_df = pd.DataFrame(aa_seqs_dict.items(), columns=['geneID', 'seq_alignment'])\n",
    "    aa_seqs_df['genomeID'] = aa_seqs_df['geneID'].str.replace('_\\d+_VOG.*', '', regex=True)\n",
    "    # if more than one gene for this vog in a genome, just take the first alignment\n",
    "    aa_seqs_df = aa_seqs_df.drop_duplicates(subset='genomeID', keep=\"first\")\n",
    "    # split alignment into columns\n",
    "    aa_seqs_df = pd.concat([aa_seqs_df['genomeID'], aa_seqs_df['seq_alignment'].apply(lambda x: pd.Series(list(x)))], axis=1)\n",
    "    aa_seqs_df = aa_seqs_df.rename(columns={c: str(vog_id)+'_pos_'+str(c) for c in aa_seqs_df.columns if c not in ['genomeID']})\n",
    "    # replace all * with '-'\n",
    "    aa_seqs_df = aa_seqs_df.replace('*', '-')\n",
    "    ## remove columns present in less than 50% of genomes\n",
    "    aa_seqs_df = aa_seqs_df.replace('-', np.nan)\n",
    "    aa_seqs_df = aa_seqs_df.dropna(thresh=int(len(aa_seqs_df)*0.5), axis=1)\n",
    "    concat_alignments_df = concat_alignments_df.merge(aa_seqs_df, how=\"outer\", on='genomeID')\n",
    "\n",
    "# sort by genomeID\n",
    "concat_alignments_df = concat_alignments_df.sort_values('genomeID').reset_index(drop=True)\n",
    "# calculate number of columns remaining (i.e. number of amino acids)\n",
    "len(concat_alignments_df.columns)-1\n",
    "#14705\n",
    "# count genomes\n",
    "genomes_count = len(concat_alignments_df)\n",
    "print(genomes_count)\n",
    "#290\n",
    "# remove genomes with <5% amino acid representation of the total alignment length\n",
    "concat_alignments_df = concat_alignments_df.dropna(subset=[col for col in concat_alignments_df.columns if col != 'genomeID'], thresh=int((len(concat_alignments_df.columns)-1)*0.05), axis=0).reset_index(drop=True)\n",
    "# count filtered genomes\n",
    "genomes_filt_count = len(concat_alignments_df)\n",
    "print(genomes_filt_count)\n",
    "#202\n",
    "print(genomes_count - genomes_filt_count)\n",
    "#88 'genomes' removed\n",
    "\n",
    "# Calculate % missing data\n",
    "concat_alignments_df[[col for col in concat_alignments_df.columns if col != 'genomeID']].isna().mean().mean()\n",
    "#0.8852660070495145 = 89% missing data\n",
    "\n",
    "# replace all nan with '-'\n",
    "concat_alignments_df = concat_alignments_df.replace(np.nan, '-')\n",
    "\n",
    "# Write out concatenated alignment file\n",
    "concat_alignments_df['seq_alignment'] = concat_alignments_df[[col for col in concat_alignments_df.columns if col != 'genomeID']].astype(str).agg(''.join, axis=1)\n",
    "concat_alignments_df = concat_alignments_df[['genomeID', 'seq_alignment']]\n",
    "concat_alignments_dict = dict(concat_alignments_df.values)\n",
    "with open('concat_alignments/hmmsearch_results_85/votus.core_genes.concatenated_alignment.faa', 'w') as write_faa:\n",
    "    for key,value in concat_alignments_dict.items():\n",
    "        write_faa.write('>' + str(key) + '\\n' + str(value) + '\\n')\n",
    "\n",
    "quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build trees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RefSeq and vOTUS combined - ultrafast bootstrap"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "caudo_core_genes_iqtree_combined_ultrafastboot.sl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -A <>\n",
    "#SBATCH -J caudo_core_genes_iqtree_combined_ultrafastboot_nmax1000\n",
    "#SBATCH --time 7-00:00:00\n",
    "#SBATCH --mem=120GB\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=32\n",
    "#SBATCH -e caudo_core_genes_iqtree_combined_ultrafastboot_nmax1000.err\n",
    "#SBATCH -o caudo_core_genes_iqtree_combined_ultrafastboot_nmax1000.out\n",
    "\n",
    "# Set up directories\n",
    "cd concat_alignments/hmmsearch_results_85\n",
    "\n",
    "# Load module\n",
    "module purge\n",
    "module load IQ-TREE/2.2.2.2-gimpi-2022a\n",
    "\n",
    "# Run IQ-tree\n",
    "iqtree -T 32 -m TEST -B 1000 -s combined.core_genes.concatenated_alignment.faa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Slurm runtime < 21 days ; MaxRss < 50 GB*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vOTUS only - ultrafast bootstrap"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "caudo_core_genes_iqtree_votus_ultrafastboot.sl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -A ga02676\n",
    "#SBATCH -J caudo_core_genes_iqtree_votus_ultrafastboot_nmax1000\n",
    "#SBATCH --time 7-00:00:00\n",
    "#SBATCH --mem=8GB\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=32\n",
    "#SBATCH -e caudo_core_genes_iqtree_votus_ultrafastboot_nmax1000.err\n",
    "#SBATCH -o caudo_core_genes_iqtree_votus_ultrafastboot_nmax1000.out\n",
    "\n",
    "# Set up directories\n",
    "cd concat_alignments/hmmsearch_results_85\n",
    "\n",
    "# Load module\n",
    "module purge\n",
    "module load IQ-TREE/2.2.2.2-gimpi-2022a\n",
    "\n",
    "# Run IQ-tree\n",
    "iqtree -T 32 -m TEST -B 1000 -s votus.core_genes.concatenated_alignment.faa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Slurm runtime < 6 hr; MaxRss < 2 GB*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
