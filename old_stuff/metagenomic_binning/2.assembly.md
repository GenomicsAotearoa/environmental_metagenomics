# Getting started

The first step in obtaining metagenome-assembled genomes (MAGs) is to assemble the metagenomic reads into a combined assembly. There are three assemblers provided under genome pipe, each of which has differing strengths and weaknesses. As a general rule, **SPAdes** is the best metagenomic assembler currently available, but it comes with a steep memory cost and comparatively long run times. Two good alternatives are **IDBA-UD** and **MegaHIT**, which typically offer slightly inferior assemblies but are significantly faster and cheaper to run.

Do note, however, that genome assembly is a highly variable process and there may be samples which assemble better under any one of the assemblers. Most literature on the subject places **SPAdes** as the top assembler on average, but this is not a guarantee for your data set. It is also worth noting that **IDBA-UD** or **MegaHIT** are more than likely to provide you with sufficient data to address your hypothesis.

1. [**SPAdes**](https://github.com/ablab/spades) v3.11.1
1. [**IDBA**](https://github.com/loneknightpy/idba) v1.1.1
1. [**MegaHIT**](https://github.com/voutcn/megahit) v1.1.3

This workflow uses software loaded by the **genome_pipe** alias.

----

### SPAdes

When performing metagenomic co-assembly, it is desirable to maintain the individuality of each sample during assembly, so that the assembler can account for coverage variation in a sample-specific manner. While this functionality is technically in **SPAdes**, in practice it never seems to work for metagenomic assemblies and it is neccessary to concatenate your files together.

To run **SPAdes** in its most basic mode, with 16 threads use the command

```bash
cat SampleA_R1.trim.fq SampleB_R1.trim.fq > Samples_R1.trim.fq
cat SampleA_R2.trim.fq SampleB_R2.trim.fq > Samples_R2.trim.fq

spades.py --meta -t 16 -1 Samples_R1.trim.fq -2 Samples_R2.trim.fq -o Sample_spades/
```

However, there are a number of things you may need to tweak for an optimal assembly. For starters, **SPAdes** imposes a 250 GB memory limit on itself while running, which is almost never enough for metagenomic assembly. The cap can be raised with the **-m** flag. Also worth consiering is the k-mer size range for performing assembly. By default, **SPAdes** starts with *k=21*, and increases in steps of 22 (k=21, k=33, k=55 etc) until it determines that it is not worth proceeding. This can be overwritten with the **-k** flag to specify the k values to assemble with.

Finally, owing to its internal read correction protocol, **SPAdes** produces a number of large temporary files while running. This shouldn't matter if you are working in the *nobackup/* directory on NeSI, but if you are concerned about running out of project space, you can redirect these temporary files to another location using the **–tmp-dir** flag.

To run **SPAdes** with all these parameters above configured:

```bash
spades.py --meta -m 900 -t 16 -k 41,61,81,101,127 -1 Samples_R1.trim.fq -2 Samples_R2.trim.fq -o Sample_spades/
```

----

### IDBA-UD

Unlike almost every other assembler, **IDBA-UD** requires interleaved fasta files as the input, instead of paired fastq files. Fortunately, it comes bundled with some tools to convert your data into this format. It also accepts only a single input file, so a concatenation step is required just like for **SPAdes**.

It’s also important to keep an eye on the length of your reads, because **IDBA-UD** uses different flags for short (**-r**) and long (**-l**) sequences. These are determined when **IDBA-UD** is compiled, and depending on your sequencing and quailty filtering your data could fall into either of these classes.

```bash
fq2fa --merge --filter SampleA_R1.trim.fq SampleA_R2.trim.fq SampleA.fna
fq2fa --merge --filter SampleB_R1.trim.fq SampleB_R2.trim.fq SampleB.fna
cat SampleA.fna SampleB.fna > Samples.fna

idba_ud --seed_kmer 21 --step 22 -l Samples.fna -o Sample_idba/
```

----

### MegaHIT

The only novel feature worth pointing out with a basic **MegaHIT** assembly is that while it has a built-in memory limit like **SPAdes**, you can specify this value as a percentage of your computers total memory rather than calculating an exact value. If this is a feature you want to use, it is set under the **-m** flag - if you pass a whole number then **MegaHIT** will treat it as a memory limit in GB. If you pass a fraction, it is treated as a percentage of total memory. The memory usage of **MegaHIT** is significantly lower than that of **SPAdes**, so if you are setting a cap it does not need to be as high as for an equivalent **SPAdes** job. Also like **SPAdes**, **MegaHIT** checkpoints its runs, so if a job fails or times out on the server, you can restart the assembly by repeating the same command, with the **–continue** flag.

```bash
megahit --k-list 41,61,81,101,127 -m 400 -t 16 \
        -1 SampleA_R1.trim.fq,SampleB_R1.trim.fq \
        -2 SampleA_R2.trim.fq,SampleB_R2.trim.fq \
        -o Sample_megahit/
```

----