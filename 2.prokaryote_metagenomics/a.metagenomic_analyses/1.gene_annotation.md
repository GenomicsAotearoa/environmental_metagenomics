# Gene prediction

To begin annotation, **prodigal** is used to create predictions for both the nucleotide and protein sequences of predicted ORFs in your genome. One
downside of **prodigal** is that it has a habit of dumping a lot of metadata into your fasta sequence header, which can confuse the downstream annotation
tools. **Prodigal** can be run on *NeSI*, with appropriate header correction, using the commands

```bash
prodigal -q -p single -f gff -i genome.fna -d genome.prod.fna -a genome.prod.faa -o genome.prod.gff

sed 's/ .*//g' genome.prod.faa > genome.prod.no_metadata.faa
sed 's/ .*//g' genome.prod.fna > genome.prod.no_metadata.fna
```

This takes the input file genome.fna and detects genes along each contig which are written out to fasta files in nucleotide (**-d**) and amino acid (**-a**) space.

*Note: **prodigal** has two modes of running, one for metagenomic data (**-p meta**) and one for genome-resolved data (**-p single**). The documentation recommends using single mode for genome data and while the majority of called genes are unaffected by the mode, differences can be seen between the outputs. Annecdotally, metagenomic mode will identify slightly fewer genes than single mode for a genome, but single mode can miss laterally transfered elements. There is not neccesarily a best choice for which version to use and this is at the users discretion.*

For unbinned data, you can change the input (`-i`) to your dereplicated contigs file. You will also need to change the running mode to metagenomic mode by modifying the flag `-p meta`.

<br>

# Protein annotation

There are a number of ways to annotate protein data in this pipeline, based either on sequence alignment or profiling motifs according to hidden Markov models (HMMs). Alignment-based annotation is based on the traditional **BLAST** software, although **BLAST** itself is rarely used in metagenomics due to its slow run time. Two rapid alternatives to **BLAST** are **usearch** and **diamond**, for which a number of databases are precompiled on *NeSI*.

## BLAST-like annotation

While **usearch** and **diamond** work in different ways, the following commands will produce output as a tab-delimited file with the following columns:

1. Query sequence
1. Target sequence
1. Alignment start position
1. Alignment stop position
1. Bitscore
1. E-value

**usearch** will utilise all threads available whereas **diamond** uses a default of 1, with the user specifying more if desired. When writing your *slurm* script, make sure to set the number of threads to the number you intend to use.

To annotate your gene predictions against *UniProt*, *UniRef100*, and *KEGG* using **usearch**, the following commands are used

```bash
usearch9.0.2132_i86linux64 -id 0.5 -evalue 0.001 -maxhits 10 -top_hits_only \
                           -userfields query+target+tlo+thi+id+bits+evalue \
                           -db $UNIPROT_udb -usearch_global genome.prod.no_metadata.faa -userout genome.uniprot.txt

usearch9.0.2132_i86linux64 -id 0.5 -evalue 0.001 -maxhits 10 -top_hits_only \
                           -userfields query+target+tlo+thi+id+bits+evalue \
                           -db $UNIREF100_udb -usearch_global genome.prod.no_metadata.faa -userout genome.uniref100.txt

usearch9.0.2132_i86linux64 -id 0.5 -evalue 0.001 -maxhits 10 -top_hits_only \
                           -userfields query+target+tlo+thi+id+bits+evalue \
                           -db $KEGG_udb -usearch_global genome.prod.no_metadata.faa -userout genome.kegg100.txt
```

*Note: There are two ways for running **usearch** alignments, either with the **-usearch_global** or **-usearch_local** alignment parameter. For a first-pass at the data, **-usearch_global** can be helpful since it has the effect of considering the database 'true', and testing how well your predicted proteins match against it. A local alignment will perform a more traditional 2-way alignment between query and target, and this will most likely give you more hits.*

To achieve equivalent outputs using **diamond** with 16 threads, use the commands

```bash
diamond blastp -p 16 -k 10 --quiet --outfmt 6 qseqid sseqid sstart send pident bitscore evalue \
               -d $UNIPROT_dmnd -q genome.prod.no_metadata.faa -o genome.uniprot.txt

diamond blastp -p 16 -k 10 --quiet --outfmt 6 qseqid sseqid sstart send pident bitscore evalue \
               -d $UNIREF100_dmnd -q genome.prod.no_metadata.faa -o genome.uniref100.txt

diamond blastp -p 16 -k 10 --quiet --outfmt 6 qseqid sseqid sstart send pident bitscore evalue \
               -d $KEGG_dmnd -q genome.prod.no_metadata.faa -o genome.kegg.txt
```

## HMM-based annotation

An alternative to alignment-based annotation is to use a statistical model (HMM) to identify conserved motifs across your gene. This can be useful when trying to identify or annotate catalytic domains, or when you have short proteins or proteins that donâ€™t annotate well across the full alignment. The standard software for performing this kind of annotation is **hmmer**, and we have three **hmmer**-compatible databases available on *NeSI*. Unlike sequence alignment based tools which often have one valid subject per query, HMM annotations can result in multiple valid hits to different parts of the same query sequence, each representing different motifs (family, domain, repeats, etc.). To annotate your genome against all three databases, use the command

```bash
hmmsearch --tblout genome.pfam.txt -E 1e-3 --cpu 10 $PFAM_hmm genome.prod.no_metadata.faa

hmmsearch --tblout genome.tigr.txt -E 1e-3 --cpu 10 $TIGRFAM_hmm genome.prod.no_metadata.faa

hmmsearch --tblout genome.eggnog.txt -E 1e-3 --cpu 10 $EGGNOG_hmm genome.prod.no_metadata.faa
```

> *A note on search algorithms*
>
> HMMER3 can perform searches in 2 ways:
> - `hmmsearch`: search profiles against database of sequences
> - `hmmscan`: search sequences against database of profiles
> 
> Under most scenarios, you are searching lots of sequences against lots of profiles. In this case, searching using `hmmsearch` algortihm (as above) will be faster for the millions of predicted genes. However, you need to be cautious if you are filtering search results by E-value, especially so if you are searching against a custom database or have few query sequences. This is because E-values are dependent on database size. With `hmmsearch`, your database size is the number of sequences; with `hmmscan`, your database size is the number of HMM profiles. See [this blog post](http://cryptogenomicon.org/hmmscan-vs-hmmsearch-speed-the-numerology.html) by the lead developer of HMMER for details. You can change the database size with the `-Z` flag in both commands.

> *A note on searching Pfam*
> 
> When searching the Pfam database, you can also tell HMMER to filter the results by a profile's [gathering threshold (GA)](https://pfam-docs.readthedocs.io/en/latest/glossary.html?highlight=gathering#gathering-threshold-ga). This is a curated bit score which a query must meet or exceed in order to be assigned to the protein family ([Finn et al., 2010](https://doi.org/10.1093/nar/gkp985)). To do this, add the flag `--cut_ga` to the HMMER command when searching against Pfam.
>
> Additionally, Pfam families with common evolutionary ancestors are grouped together in *clans*. When performing hmmsearch/hmmscan against Pfam, outputs might have overlapping hits against the same region. The curators of Pfam have written a script ([pfam_scan.pl](https://ftp.ebi.ac.uk/pub/databases/Pfam/Tools/PfamScan.tar.gz)) that can identify these overlaps and return the best scoring hit within the clan.

The output from HMMER can be rather voluminous, please refer to the exceptionally well written [User Guide](http://eddylab.org/software/hmmer/Userguide.pdf) for how to interpret the output tables.

## Signal peptides

As an extension to gene annotation, if it often valuable to look at the signal peptides attached to gene predictions to make determinations as to whether the proteins are exported from the organisms cell or embedded in the membrane (for example, signalling receptors, and some respiratory proteins).

Performing this prediction requires knowledge as to whether your genome is from a Gram negative or positive organism (if prokaryotic) or if it is from a eukaryotic organism. If you have a prokaryotic genome, the cell wall structure (Gram straining) can be deduced from the phylum to which your genome is classified.

Performing the annotation in each way is given below, but for each bin, only perform a single step.

```bash
signalp -f short -s best -c 0 -t gram- genome.prod.no_metadata.faa > genome.signalp

signalp -f short -s best -c 0 -t gram+ genome.prod.no_metadata.faa > genome.signalp

signalp -f short -s best -c 0 -t euk genome.prod.no_metadata.faa > genome.signalp
```

*Update: SignalP version 6 implements a different model for signal peptide prediction that allows it to be somewhat taxonomically agnostic ([Teufel et al., 2022](https://doi.org/10.1038/s41587-021-01156-3)). For prokaryotic sequences, this means that you can run the programme without stating the Gram stain status of the organism. This may be better for metagenomic sequences (which could be of unknown/uncertain origin).*

<br>

# Custom databases

With both alignment-based and HMM-based annotation, you can create custom databases if your study question(s) require it. 

For **usearch**, you can use a fasta file as a database (as such, it will also accept databases in the nucleic acid space). However, with large databases, creating an indexed database will greatly improve search speeds. For **diamond**, it will only run on an indexed protein sequence database. The commands below will create an indexed database based on your custom fasta file

```bash
# Create USEARCH indexed database from fasta file
usearch9.0.2132_i86linux64 -makeudb_usearch reference_sequences.faa -output database.udb

# Create DIAMOND indexed databased from fasta file
diamond makedb --in reference_sequences.faa -d database.dmnd
```

Creating a database from scratch for HMM-based annotations will require multiple sequence alignments (MSA) and curation. Curating and creating MSAs are beyond the scope of this workflow. However, there are compiled HMM profiles/databases that are curated (e.g. dbCAN2) and you simply have to "press" the files into a searchable database. You can also concatenate multiple HMM profiles to create a custom database. 

The lines below will cover how to create a HMM database for HMMER3. 

```bash
# Starting from MSAs, assuming the file contains a collection of MSAs in stockholm format.
hmmbuild profiles.hmm alignments.sto
# The line above will create the HMM profile database profiles.hmm from input alignments.sto

# If you are working with MSAs for different domains/proteins in other formats, each profile will need to be built separately then concatenated.
# For example, if you have 2 protein alignments:
hmmbuild profile_A.hmm alignment_A.aln
hmmhuild profile_B.hmm alignment_B.aln

cat profile_A.hmm profile_B.hmm > profiles.hmm

# Starting from HMM profiles, they will need to be "pressed" to be searched by hmmscan
hmmpress profiles.hmm
# If using hmmsearch algorithm, you do not need to "press" the profiles.
```
