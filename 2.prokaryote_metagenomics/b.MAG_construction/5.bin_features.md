# Introduction
Now that we have a set of refined, dereplicated bins, the final step prior to annotation and analysis is to get a final evaluation of the bin quality (do this with **CheckM** as shown [here](2.initial_binning.md#5-bin-evaluation)), identify genomic features (e.g. rRNA/tRNA/ncRNA sequences and CRISPR-Cas), and assign taxonomy to each bin. A [recently published standard](https://www.ncbi.nlm.nih.gov/pubmed/28787424) for MAG (metagenome-assembled genome, what we call a bin) quality defines categories of quality as follows:

|State|Completeness|Contaimnation|Assembly quality|
|:---|:---:|:---:|:---|
|Finished|-|-|Single contiguous sequence without gaps or ambiguities with a consensus error rate equivalent to Q50 or better.|
|High-quality draft|>90%|<5%|Multiple fragments where gaps span repetitive regions. Presence of the 23S, 16S, and 5S rRNA genes and at least 18 tRNAs.|
|Medium-quality draft|â‰¥50%|<10%|Many fragments with little to no review of assembly other than reporting of standard assembly statistics.|
|Low-quality draft|<50%|<10%|Many fragments with little to no review of assembly other than reporting of standard assembly statistics.|

However, bin quality can be a bit of a tricky beast to deal with. It is often difficult to recover rRNA elements from metagenomic assemblies, so it is common to have bins with a high completeness but comparatively low standard. There is also no guarantee that a high-quality draft will actually be of value to a study. Even at 90% complete, there will be some genes missing from the bin and therefore a degree of false negative findings in annotation. We can hedge this to a degree by having an accurate taxonomy for each bin, allowing us to predict the functionality that '*should*' be present and to identify genes that are suggestive of function. Finally, reverse is also true. A low-quality draft bin might be useless for any real genomic analysis, but might consist solely of an important biosynthetic cluster of genes and some housekeeping markers that can be used for taxonomic prediction. This alone may be all that is needed for answering a hypothesis.

So in summary - quality thresholds are useful, but only a guideline and not a reflection of biological usefulness of the data.

# RNA
## rRNA

Probably the first thing you want to do with a new genome or bin is to search for 16S and 23S rRNA sequences to try to get a rough idea of the taxonomy of the organism. These are valuable for classifying your organism, and this information is great if you need to link your data to amplicon sequences, or the scientific literature. This is a pretty quick program to run, so although it can use multiple threads it's pretty unlikely you'll need them.

By deafult, **MeTaxa2** will attempt to identify SSU and LSU sequences that match bacteria, archaea, chloroplast, eukaryotic, and mitochondria models. The specific outputs will be appended to the end of the file name specified with the **-o** flag. You can examine these yourself, but by default the **annotationAggregrator.py** script (detailed [here](https://github.com/GenomicsAotearoa/environmental_metagenomics/blob/master/metagenomic_annotation/3.aggregation.md)) will parse all of these outputs and summarise their results, so there's no need to curate the outputs.

```bash
metaxa2 --cpu 1 -g ssu -i genome.fna -o genome.metaxa.ssu

metaxa2 --cpu 1 -g lsu -i genome.fna -o genome.metaxa.lsu
```

## tRNA and tmRNA

**Aragorn** can be used to predict tRNA and tmRNAs in your genome. There are a range of parameters to optimise with this program, but for a decent starting point

```bash
aragorn -m -t -gcstd -l -a -q -rn -fon -o genome.aragorn genome.fna
```

These parameter choices are:

1. **-m**: Search for tmRNA sequences
1. **-t**: Search for tRNA sequences
1. **-gcstd**: Use standard genetic code.
1. **-l**: Assume that each sequence has a linear topology (search does not assume a circular/complete genome)
1. **-a**: Print out tRNA domain for tmRNA genes.
1. **-q**: Dont print configuration line
1. **-rn**: Repeat sequence name before summary information
1. **-fon**: Output file format as fasta, without fold modelling
1. **-o**: Output file name (default is stdout)

This will produce the output that the aggregator script expects, but as long as the **-fon** and **-a** flags are present **annotationAggregrator.py** should handle variations without issue.

## ncRNA

Non-coding RNAs (ncRNA) can be predicted in your genome using **Infernal**, which is produced by the same people who created **hmmer**. It uses a statistical model similar to an HMM, called a covariance model (CM) to identify these RNA structures. Prediction is performed by comparing your genome against the *Rfam* database, and requires you to know the approximate size of your genome to accurately calculate match significance. This can be calculated on the command line using bash, then fed directly into **Infernal**.

```bash
totChar=`grep -v '>' genome.fna | wc -m`
nLines=`grep -v '>' genome.fna | wc -l`
nt=$((totChar - nLines))
ntM=`echo 'scale=5 ; $nt / 1000000' | bc`

cmscan -Z $ntM --cut_ga --nohmmonly --tblout genome.rfam $RFAM_cm genome.fna
```

# CRISPR-Cas

Everyone loves CRISPR-Cas! Predict CRISPR sequences in your genomes by creating a text file of genome names/paths, then pass it to **CRISPRDisco**

```bash
source activate /nesi/project/uoa02469/Software/PipelineSetup/crisprdisco_env

echo ",Path" > disco_input.csv
echo ",0,genome.fna" > disco_input.csv

disco disco_input.csv
```

# Taxonomic classification using GTDB-Tk

The **GTDB-TK** is a stripped down version of the larger **Genome Taxonomy Database** ([website](https://gtdb.ecogenomic.org/), [publication](https://www.ncbi.nlm.nih.gov/pubmed/30148503)) project, run out of Philip Hugenholtz's lab at the Univesity of Queensland. It makes use of over 125,000 publicly available bacterial and archaeal genomes to produce a phylogeny based on core marker genes, similar to those used by **CheckM**. The **GTDB-TK** software automatically identifies markers in genomes and creates a representative protein alignment of the main alignment used by the **GTDB**. This alignment is then inserted into a guide tree and the most likely taxonomy for each genome calculated by the placement of the genome in the tree, and the length of its branch from nearest neighbours.

If you're working with this software, note that the **GTDB** as a whole is aiming to make significant changes to prokaryotic nomenclature and contains a number of differences from accepted taxonomy. There are generally published manuscripts that report these differences (for example, [Chuvochina *et al.*](https://doi.org/10.1016/j.syapm.2018.07.003), [Waite *et al.*](https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118960608.bm00040)), and there is ongoing collaboration between the **GTDB** team and the ICNP (the effective arbiters of prokaryote taxonomy) to make **GTDB** proposals official. You are advised to check any **GTDB** classifications against other references to ensure the name makes sense and to correct names to their currently accepted versions as appropriate (for example, the phylum *Bacteroidetes* is reported as *Bacteroidota* in **GTDB-TK**).

```bash
gtdbtk classify_wf \
  -x fa \
  --cpus 10 \
  --genome_dir user_bins/ \
  --out_dir gtdbtk_output/
```

There are a few output files of interest here. Most importantly, note that bacterial and archaeal genomes are reported in different files, so make sure that you check both for the placement of your bins. If you want a more robust tree to confirm placement, you can extract reference genomes from the *msa* files and use them in any good phylogenetic inference tool.




