# Introduction

Once the initial bins are made, they need to be processed down into the best representatives from the data. It is not uncommon for binning programs to produce dozens of bins, but where the majority consist of only a few contigs with minimal scientific value. Refinement of bins therefore happens in two steps. First, the bins produced by multiple binning tools are compared to identify which bins are produced by all tools, and which are unique (**DAS_Tool**). The best representative bins are taken from this process, and further dereplicated into species-level representatives across the entire data set (**dRep**). The important difference between these two steps is that **DAS_Tool** works for bins produced from the same assembly, by different binning tools. **dRep** is applied to bins that are distinct at the contig level, but may be closely related in terms of average nucleotide identity.

<br>

# De-replicating within an assembly 

**DAS_Tool** is a handy program that looks at the output of multiple binning tools run over a single assembly, and identifies which bins are duplicates of each other. It then dereplicates the initial binning down into a set of non-redundant bins for future processing. This program is simple to use, but requires a bit of preprocessing to get the correct input files. This can generally be done on the command line, but may need to be tweaked to your exact naming and file organisation.

Be aware that if you're asking your binning tool to report unbinned contigs, these commands will pull them into the DAS Tool workflow and mess with results. Make sure to remove/rename any of these files if they are present.

```bash
# Create a MetaBAT input file
grep ">" metabat/*.fa | sed 's/.fa:>/\t/g' | awk 'OFS="\t" {print $2,$1}' > metabat.txt

# Create a MaxBin input file
grep ">" maxbin/*.fasta | sed 's/.fasta:>/\t/g' | awk 'OFS="\t" {print $2,$1}' > maxbin.txt

# Create a CONCOCT input file
grep ">" concoct/fasta_bins/*.fna | sed 's/.fna:>/\t/g' | awk 'OFS="\t" {print $2,$1}' > concoct.txt

# Run DAS_Tool
mkdir dastool/

DAS_Tool -i metabat.txt,maxbin.txt,concoct.txt \
         -l metabat,maxbin,concoct \
         -t 10 \
         --write_bins 1 \
         --search_engine blast \
         -c contigs.fna \
         -o dastool/
```

<br>

# De-replicating across assemblies

Once we have selected the best 'non-redundant' bins using **DAS_Tool**, we can perform further dereplication via average nucleotide identity (ANI) using **dRep**. Unlike **DAS_Tool**, this tool uses ANI to identify equivalent genomes in a collection, returning only the best-quality representatives. Because this approach is based on genome sequence data rather than contig names, it can be used between assemblies to identify genomes or MAGs that have been detected in multiple samples or assemblies.

**dRep** uses the completeness and contamination estimations from **CheckM** to assess bin quality, and the default behaviour is to run this program over your bins during a run. However, **dRep** does not fully exploit the multithread nature of **CheckM** and this can result in slow run times. I prefer to run **CheckM** first, then reformat the output file into a form that **dRep** can interpret.

<!---
*Note: There is a more detailed breakdown of the **CheckM** tool in the [final evaluation](https://github.com/GenomicsAotearoa/environmental_metagenomics/blob/master/metagenomic_binning/6.final_evaluation.md) notebook.*
--->


```bash
# Reformat CheckM output
echo "genome,completeness,contamination" > dRep.genomeInfo
cut -f1,12 bin_summary.txt | sed 's/\t/.fa,/g' > p1.txt
cut -f13 bin_summary.txt > p2.txt
paste -d "," p1.txt p2.txt | tail -n+2 >> dRep.genomeInfo

# Run dRep
dRep dereplicate -p 10 --genomeInfo dRep.genomeInfo -g dastool/_DASTool_bins/* dRep_output/
```

