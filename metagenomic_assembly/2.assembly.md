# Getting started

The first step in obtaining metagenome-assembled genomes (MAGs) is to assemble the metagenomic reads into a combined assembly. There are three assemblers provided under genome pipe, each of which has differing strengths and weaknesses. As a general rule, **SPAdes** is the best metagenomic assembler currently available, but it comes with a steep memory cost and comparatively long run times. Two good alternatives are **IDBA-UD** and **MegaHIT**, which typically offer slightly inferior assemblies but are significantly faster and cheaper to run.

Do note, however, that genome assembly is a highly variable process and there may be samples which assemble better under any one of the assemblers. Most literature on the subject places **SPAdes** as the top assembler on average, but this is not a guarantee for your data set. It is also worth noting that **IDBA-UD** or **MegaHIT** are more than likely to provide you with sufficient data to address your hypothesis. [Vollmers et al. (2017)](https://doi.org/10.1371/journal.pone.0169662) provides some guidance for choosing assemblers:
> "If micro diversity is not a major issue, and the primary research goal is to bin and reconstruct representative bacterial genomes from a given environment, metaSPAdes should clearly be the assembler of choice... If micro diversity is however an issue, or if the degree of captured diversity is far more important than contig lengths, then IDBA-UD or MegaHIT should be preferred."

1. [**SPAdes**](https://github.com/ablab/spades) v3.11.1
1. [**IDBA**](https://github.com/loneknightpy/idba) v1.1.1
1. [**MegaHIT**](https://github.com/voutcn/megahit) v1.1.3

If you are working within the Handley lab, this workflow uses software loaded by the **genome_pipe** alias.

### Single or co-assemblies?
Depending on the study question, and available time and computational resources, you may wish to do single assemblies (i.e. separate assemblies per sample) or some variety of co-assemblies. Examples of approaches to co-assemblies:
- Full co-assembly (i.e. all samples assembled together)
- Co-assemblies based on sampling design/strategy (e.g. separate co-assemblies of sediment and water column samples, co-assemblies based on discrete time points)

Some benefits of co-assemblies: 
- Higher read-depth
- Potentially better at recovering rare taxa that occur in more than 1 sample
- One reference assembly for read mapping (if working from a full co-assembly) 

[Vosloo et al. (2021)](https://doi.org/10.1128/Spectrum.01434-21) compares different assembly and binning strategies and may provide some insight to help you decide on the best course of action.

*Note: The following workflow is geared towards co-assemblies. If running single assemblies, simply omit concatenation by sample.*

----
### SPAdes

When performing metagenomic co-assembly, it is desirable to maintain the individuality of each sample during assembly, so that the assembler can account for coverage variation in a sample-specific manner. While this functionality is technically in **SPAdes**, in practice it never seems to work for metagenomic assemblies and it is neccessary to concatenate your files together.

To run **SPAdes** in its most basic mode, with 16 threads use the command

```bash
cat SampleA_R1.trim.fq SampleB_R1.trim.fq > Samples_R1.trim.fq
cat SampleA_R2.trim.fq SampleB_R2.trim.fq > Samples_R2.trim.fq

spades.py --meta -t 16 -1 Samples_R1.trim.fq -2 Samples_R2.trim.fq -o Sample_spades/
```

However, there are a number of things you may need to tweak for an optimal assembly. For starters, **SPAdes** imposes a 250 GB memory limit on itself while running, which is almost never enough for metagenomic assembly. The cap can be raised with the **-m** flag. Also worth consiering is the k-mer size range for performing assembly. By default, **SPAdes** starts with *k=21*, and increases in steps of 22 (k=21, k=33, k=55 etc) until it determines that it is not worth proceeding. This can be overwritten with the **-k** flag to specify the k values to assemble with.

Finally, owing to its internal read correction protocol, **SPAdes** produces a number of large temporary files while running. This shouldn't matter if you are working in the *nobackup/* directory on NeSI, but if you are concerned about running out of project space, you can redirect these temporary files to another location using the **–tmp-dir** flag.

To run **SPAdes** with all these parameters above configured:

```bash
spades.py --meta -m 900 -t 16 -k 41,61,81,101,127 -1 Samples_R1.trim.fq -2 Samples_R2.trim.fq -o Sample_spades/
```

----

### IDBA-UD

Unlike almost every other assembler, **IDBA-UD** requires interleaved fasta files as the input, instead of paired fastq files. Fortunately, it comes bundled with some tools to convert your data into this format. It also accepts only a single input file, so a concatenation step is required just like for **SPAdes**.

It’s also important to keep an eye on the length of your reads, because **IDBA-UD** uses different flags for short (**-r**) and long (**-l**) sequences. These are determined when **IDBA-UD** is compiled, and depending on your sequencing and quailty filtering your data could fall into either of these classes.

```bash
fq2fa --merge --filter SampleA_R1.trim.fq SampleA_R2.trim.fq SampleA.fna
fq2fa --merge --filter SampleB_R1.trim.fq SampleB_R2.trim.fq SampleB.fna
cat SampleA.fna SampleB.fna > Samples.fna

idba_ud --seed_kmer 21 --step 22 -l Samples.fna -o Sample_idba/
```

----

### MegaHIT

The only novel feature worth pointing out with a basic **MegaHIT** assembly is that while it has a built-in memory limit like **SPAdes**, you can specify this value as a percentage of your computers total memory rather than calculating an exact value. If this is a feature you want to use, it is set under the **-m** flag - if you pass a whole number then **MegaHIT** will treat it as a memory limit in GB. If you pass a fraction, it is treated as a percentage of total memory. The memory usage of **MegaHIT** is significantly lower than that of **SPAdes**, so if you are setting a cap it does not need to be as high as for an equivalent **SPAdes** job. Also like **SPAdes**, **MegaHIT** checkpoints its runs, so if a job fails or times out on the server, you can restart the assembly by repeating the same command, with the **–continue** flag.

```bash
megahit --k-list 41,61,81,101,127 -m 400 -t 16 \
        -1 SampleA_R1.trim.fq,SampleB_R1.trim.fq \
        -2 SampleA_R2.trim.fq,SampleB_R2.trim.fq \
        -o Sample_megahit/
```

----

### Optional: Filtering short contigs using seqmagick

When assembling metagenomic data, we expect to encounter a large number of very short sequences of several hundred base pairs in length. Biologically, these are not really that useful since they are too short to reliably encode genes, and they inflate noise in the binning process. We use the absolutely amazing tool [**seqmagick**](https://fhcrc.github.io/seqmagick/) to remove short read from the assembly. Typically we exclude sequences less than 2,000 bp in length, but this can be changed according to the quality of your assembly.

```bash
seqmagick convert --min-length 2000 your_assembly.fasta contigs.fna
```
