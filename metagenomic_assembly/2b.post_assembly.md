# To bin or not to bin?

After assembling metagenomic data, you will need to evaluate the quality of your assembly. This [page](https://github.com/GenomicsAotearoa/metagenomics_summer_school/blob/master/materials/day1/ex5_evaluating_assemblies.md#evaluate-the-assemblies) has guidance on how to do that depending on the type of data you have. Depending on your study question, you might need/want to recover metagenome-assembled genomes (MAGs) for further analyses. If binning is necessary, please refer to the [**metagenomic_binning**](https://github.com/JSBoey/environmental_metagenomics/tree/master/metagenomic_binning) directory for the relevant workflow. Otherwise, you will need to dereplicate the assembled contigs then continue on to annotate them. This document will cover contig dereplication.

----

## Dereplicate contigs
If you have more than one co-assembly, it is necessary to dereplicate similar and/or identical contigs across the multiple assemblies to obtain a set of dereplicated contigs for downstream steps. There are multiple options for this. Generally you will dereplicate based on a similarity threshold (and/or similarity threshold over *x* proportion of the shortest contig). This can be done via *nucmer*/*mummer* (which may have more optional parameters for fine tuning the dereplication process). The workflow below will use *dedupe.sh* from **BBMap**.

> **Caveat**
>
> Properly dereplicating contigs across assemblies is a generally tricky process in the case where contigs derived from the same genome overlap but have overhangs at both ends. Take the following example:
> ```
> ----------------TACC[...]AGATCAAGGACCAACTGGACC[...]
> [...]ATTGAAGTAGCTACC[...]AGATCAAG------------------
> ```
> The contigs above may be from the same (or closely related) genomes, in which case it would be ideal to have them dereplicated into a single representative contig. This is especially important if there is a gene(s) in the overlap region that you want to map reads to. Retaining both contigs results in splitting the reads over both contigs, falsely deflating the overall coverage count for the gene(s). 
>
> However, this remains problematic to resolve. For now, we will accept that the dereplication process might not be ideal. If you have co- *and* individual (per sample) assemblies, you likely increase the odds of recovering one assembled contig from these sources that covers the full expanse of the other contigs from this genome(s) (i.e. ideally the other related contigs are contained within a longer one). 

### Concatenate contigs from multiple assemblies

*Optional: Modify contig headers*

On rare occasions, different assemblies can contain contigs with identical headers. This is problematic for downstream processing. Modify contig headers to include the assembly ID (assumed that it is the filename) before concatenation to avoid this issue.

```sh
# Copy all relevent assembly files into a working directory prior to running the lines below
for file in *.fna; do
  assemblyID=$(basename ${file} .fna)
  sed -i -e "s/>/>${assemblyID}_/g" ${file}
done

# Concatenate assembly files
cat *.fna > all_contigs.fna
```

### Dereplicate contigs using dedupe.sh
Depending on how much you need/want to reduce the dataset to, you may want to **consider modifying the minidentity threshold**. This can change the extent to which contigs from very closely related organisms are dereplicated together and/or allow for rare sequencing errors. See this [page](https://jgi.doe.gov/data-and-tools/bbtools/bb-tools-user-guide/dedupe-guide/) for context. Run `dedupe.sh -h` for more options/parameters.

```sh
# Load module
module purge
module load BBMap/38.90-gimkl-2020a

# Run dedupe.sh on concatenated assemblies
dedupe.sh threads=8 minidentity=100 overwrite=t \
  in=all_contigs.fna \
  out=dereplicated_contigs.fna
```


